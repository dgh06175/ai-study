{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-09T01:19:48.788662Z",
     "start_time": "2025-06-09T01:19:40.851280Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_in = 64\n",
    "n_mid = 32\n",
    "n_latent = 2\n",
    "n_out = 64\n",
    "eta = 0.001\n",
    "batch_size = 32\n",
    "epochs = 50"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T01:19:48.819570Z",
     "start_time": "2025-06-09T01:19:48.803382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "digits = load_digits()\n",
    "x = digits.data / 16.0\n",
    "t = digits.target\n",
    "\n",
    "x_train, x_test = train_test_split(x, test_size=0.2, random_state=42)"
   ],
   "id": "a43e2f74dd11c2f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T01:19:48.831811Z",
     "start_time": "2025-06-09T01:19:48.827140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MiddleLayer:\n",
    "    def __init__(self, n_in, n_out):\n",
    "        self.w = np.random.randn(n_in, n_out) * np.sqrt(2 / n_in)\n",
    "        self.b = np.zeros(n_out)\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.u = np.dot(x, self.w) + self.b\n",
    "        self.y = np.maximum(0, self.u)\n",
    "        return self.y\n",
    "    def backward(self, grad_y):\n",
    "        delta = grad_y * (self.u > 0)\n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        grad_x = np.dot(delta, self.w.T)\n",
    "        return grad_x\n",
    "    def update(self, eta):\n",
    "        self.w -= eta * self.grad_w\n",
    "        self.b -= eta * self.grad_b"
   ],
   "id": "4e851fd68a163618",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T01:19:48.924608Z",
     "start_time": "2025-06-09T01:19:48.920449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ParamsLayer:\n",
    "    def __init__(self, n_in, n_out):\n",
    "        self.w = np.random.randn(n_in, n_out) / np.sqrt(n_in)\n",
    "        self.b = np.zeros(n_out)\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.u = np.dot(x, self.w) + self.b\n",
    "        self.y = self.u\n",
    "        return self.y\n",
    "    def backward(self, grad_y):\n",
    "        self.grad_w = np.dot(self.x.T, grad_y)\n",
    "        self.grad_b = np.sum(grad_y, axis=0)\n",
    "        grad_x = np.dot(grad_y, self.w.T)\n",
    "        return grad_x\n",
    "    def update(self, eta):\n",
    "        self.w -= eta * self.grad_w\n",
    "        self.b -= eta * self.grad_b"
   ],
   "id": "3644cea7fd78e4dd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T01:19:48.941212Z",
     "start_time": "2025-06-09T01:19:48.937904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LatentLayer:\n",
    "    def forward(self, mu, log_var):\n",
    "        self.mu = mu\n",
    "        self.log_var = log_var\n",
    "        self.epsilon = np.random.randn(*mu.shape)\n",
    "        self.z = mu + np.exp(0.5 * log_var) * self.epsilon\n",
    "        return self.z\n",
    "    def backward(self, grad_z):\n",
    "        grad_mu = grad_z\n",
    "        grad_log_var = grad_z * self.epsilon * 0.5 * np.exp(0.5 * self.log_var)\n",
    "        return grad_mu, grad_log_var"
   ],
   "id": "595d1dcb2bcacaac",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T01:19:49.076869Z",
     "start_time": "2025-06-09T01:19:49.073056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class OutputLayer:\n",
    "    def __init__(self, n_in, n_out):\n",
    "        self.w = np.random.randn(n_in, n_out) / np.sqrt(n_in)\n",
    "        self.b = np.zeros(n_out)\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.u = np.dot(x, self.w) + self.b\n",
    "        self.y = 1 / (1 + np.exp(-self.u))\n",
    "        return self.y\n",
    "    def backward(self, t):\n",
    "        delta = (self.y - t)\n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        grad_x = np.dot(delta, self.w.T)\n",
    "        return grad_x\n",
    "    def update(self, eta):\n",
    "        self.w -= eta * self.grad_w\n",
    "        self.b -= eta * self.grad_b"
   ],
   "id": "765097244c351fca",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T01:19:49.121970Z",
     "start_time": "2025-06-09T01:19:49.118178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "enc_mid = MiddleLayer(n_in, n_mid)\n",
    "enc_mu = ParamsLayer(n_mid, n_latent)\n",
    "enc_logvar = ParamsLayer(n_mid, n_latent)\n",
    "latent_layer = LatentLayer()\n",
    "\n",
    "dec_mid = MiddleLayer(n_latent, n_mid)\n",
    "dec_out = OutputLayer(n_mid, n_out)"
   ],
   "id": "4ae81c9ac495bfc0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T01:19:49.148159Z",
     "start_time": "2025-06-09T01:19:49.145235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward(x):\n",
    "    h = enc_mid.forward(x)\n",
    "    mu = enc_mu.forward(h)\n",
    "    log_var = enc_logvar.forward(h)\n",
    "    z = latent_layer.forward(mu, log_var)\n",
    "    h_dec = dec_mid.forward(z)\n",
    "    y = dec_out.forward(h_dec)\n",
    "    return y, mu, log_var, z"
   ],
   "id": "304ceb65fd567acf",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T01:19:49.182952Z",
     "start_time": "2025-06-09T01:19:49.179771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def vae_loss(y, x, mu, log_var):\n",
    "    rec_loss = -np.sum(x * np.log(y + 1e-7) + (1 - x) * np.log(1 - y + 1e-7), axis=1)\n",
    "    kl_loss = -0.5 * np.sum(1 + log_var - mu**2 - np.exp(log_var), axis=1)\n",
    "    return np.mean(rec_loss + kl_loss), np.mean(rec_loss), np.mean(kl_loss)"
   ],
   "id": "e5c2dd6203984b80",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T01:19:49.214077Z",
     "start_time": "2025-06-09T01:19:49.210886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def backward(x, y, mu, log_var, z):\n",
    "    grad_y = dec_out.backward(x)\n",
    "    grad_h_dec = dec_mid.backward(grad_y)\n",
    "\n",
    "    grad_z = grad_h_dec\n",
    "    grad_mu, grad_log_var = latent_layer.backward(grad_z)\n",
    "\n",
    "    grad_h_mu = enc_mu.backward(grad_mu + (mu / x.shape[0]))\n",
    "\n",
    "    grad_h_logvar = enc_logvar.backward(grad_log_var + 0.5 * (np.exp(log_var) - 1) / x.shape[0])\n",
    "    grad_h = grad_h_mu + grad_h_logvar\n",
    "    enc_mid.backward(grad_h)"
   ],
   "id": "21a00fb5991508a2",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T01:19:49.232403Z",
     "start_time": "2025-06-09T01:19:49.229455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update():\n",
    "    enc_mid.update(eta)\n",
    "    enc_mu.update(eta)\n",
    "    enc_logvar.update(eta)\n",
    "    dec_mid.update(eta)\n",
    "    dec_out.update(eta)"
   ],
   "id": "95d91d1d42de782b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-09T01:19:50.749554Z",
     "start_time": "2025-06-09T01:19:49.251881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(epochs):\n",
    "    idx = np.random.permutation(len(x_train))\n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "        x_mb = x_train[idx[i:i+batch_size]]\n",
    "        y, mu, log_var, z = forward(x_mb)\n",
    "        loss, rec_loss, kl_loss = vae_loss(y, x_mb, mu, log_var)\n",
    "        backward(x_mb, y, mu, log_var, z)\n",
    "        update()\n",
    "\n",
    "    # 평가 및 출력\n",
    "    y_test, mu_test, log_var_test, z_test = forward(x_test)\n",
    "    test_loss, test_rec_loss, test_kl_loss = vae_loss(y_test, x_test, mu_test, log_var_test)\n",
    "    print(f'Epoch {epoch+1}, Test Loss: {test_loss:.4f}, Rec: {test_rec_loss:.4f}, KL: {test_kl_loss:.4f}')\n"
   ],
   "id": "831d42dd5efe5895",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Test Loss: 33.4018, Rec: 26.9222, KL: 6.4796\n",
      "Epoch 2, Test Loss: 32.6112, Rec: 25.9380, KL: 6.6732\n",
      "Epoch 3, Test Loss: 31.9322, Rec: 25.6519, KL: 6.2803\n",
      "Epoch 4, Test Loss: 32.0274, Rec: 25.4162, KL: 6.6112\n",
      "Epoch 5, Test Loss: 32.3629, Rec: 25.3857, KL: 6.9772\n",
      "Epoch 6, Test Loss: 30.9910, Rec: 25.3420, KL: 5.6490\n",
      "Epoch 7, Test Loss: 32.4015, Rec: 25.0574, KL: 7.3441\n",
      "Epoch 8, Test Loss: 31.0488, Rec: 24.8779, KL: 6.1709\n",
      "Epoch 9, Test Loss: 31.9982, Rec: 24.8006, KL: 7.1976\n",
      "Epoch 10, Test Loss: 30.8647, Rec: 24.8175, KL: 6.0471\n",
      "Epoch 11, Test Loss: 31.2139, Rec: 24.4452, KL: 6.7687\n",
      "Epoch 12, Test Loss: 32.0736, Rec: 24.4425, KL: 7.6311\n",
      "Epoch 13, Test Loss: 30.8612, Rec: 24.1225, KL: 6.7387\n",
      "Epoch 14, Test Loss: 30.6096, Rec: 24.2802, KL: 6.3294\n",
      "Epoch 15, Test Loss: 30.5848, Rec: 24.0515, KL: 6.5333\n",
      "Epoch 16, Test Loss: 31.1975, Rec: 23.9947, KL: 7.2028\n",
      "Epoch 17, Test Loss: 30.2954, Rec: 23.8194, KL: 6.4760\n",
      "Epoch 18, Test Loss: 30.6222, Rec: 23.9140, KL: 6.7082\n",
      "Epoch 19, Test Loss: 31.2319, Rec: 23.7922, KL: 7.4397\n",
      "Epoch 20, Test Loss: 30.0778, Rec: 24.1531, KL: 5.9246\n",
      "Epoch 21, Test Loss: 30.5727, Rec: 23.4673, KL: 7.1054\n",
      "Epoch 22, Test Loss: 30.2232, Rec: 23.3905, KL: 6.8327\n",
      "Epoch 23, Test Loss: 30.2403, Rec: 23.1952, KL: 7.0451\n",
      "Epoch 24, Test Loss: 29.8116, Rec: 23.2942, KL: 6.5174\n",
      "Epoch 25, Test Loss: 30.3078, Rec: 23.2135, KL: 7.0943\n",
      "Epoch 26, Test Loss: 29.9817, Rec: 23.0156, KL: 6.9662\n",
      "Epoch 27, Test Loss: 30.5716, Rec: 23.1413, KL: 7.4303\n",
      "Epoch 28, Test Loss: 30.2918, Rec: 23.1330, KL: 7.1588\n",
      "Epoch 29, Test Loss: 29.5885, Rec: 22.8186, KL: 6.7698\n",
      "Epoch 30, Test Loss: 29.9926, Rec: 22.7649, KL: 7.2277\n",
      "Epoch 31, Test Loss: 29.5747, Rec: 22.7208, KL: 6.8540\n",
      "Epoch 32, Test Loss: 29.8813, Rec: 22.6643, KL: 7.2170\n",
      "Epoch 33, Test Loss: 29.7754, Rec: 22.6180, KL: 7.1574\n",
      "Epoch 34, Test Loss: 29.5484, Rec: 22.5879, KL: 6.9605\n",
      "Epoch 35, Test Loss: 30.0712, Rec: 22.5587, KL: 7.5125\n",
      "Epoch 36, Test Loss: 29.7327, Rec: 22.4802, KL: 7.2525\n",
      "Epoch 37, Test Loss: 29.7395, Rec: 22.3993, KL: 7.3402\n",
      "Epoch 38, Test Loss: 29.5260, Rec: 22.3621, KL: 7.1639\n",
      "Epoch 39, Test Loss: 29.7077, Rec: 22.4004, KL: 7.3073\n",
      "Epoch 40, Test Loss: 29.9118, Rec: 22.3581, KL: 7.5536\n",
      "Epoch 41, Test Loss: 29.6206, Rec: 22.2405, KL: 7.3800\n",
      "Epoch 42, Test Loss: 29.4577, Rec: 22.3007, KL: 7.1570\n",
      "Epoch 43, Test Loss: 29.2044, Rec: 22.3140, KL: 6.8904\n",
      "Epoch 44, Test Loss: 29.5282, Rec: 22.2510, KL: 7.2772\n",
      "Epoch 45, Test Loss: 29.6834, Rec: 22.3078, KL: 7.3756\n",
      "Epoch 46, Test Loss: 29.6351, Rec: 22.2292, KL: 7.4059\n",
      "Epoch 47, Test Loss: 29.6488, Rec: 22.1193, KL: 7.5295\n",
      "Epoch 48, Test Loss: 29.5139, Rec: 22.1464, KL: 7.3675\n",
      "Epoch 49, Test Loss: 29.5030, Rec: 22.1175, KL: 7.3855\n",
      "Epoch 50, Test Loss: 29.3003, Rec: 22.1368, KL: 7.1635\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
